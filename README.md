# Bayesian Marketâ€“Sports Forecasting System for the NBA

## ğŸ¯ Final Project Definition
**Core research question**

When should we trust the market, when should we trust a statistical sports model, and how does that change over time?

Markets come from Kalshi / Polymarket, but you treat them as noisy belief aggregators, not ground truth.

## System Overview (mental model)

Youâ€™re building a probabilistic ensemble with learned trust:

```
NBA Data â”€â”€â–¶ Bayesian Sports Model â”€â”€â–¶ P_model Â± Ïƒ_model
Market Odds â”€â–¶ Belief Dynamics Model â”€â–¶ P_market Â± Ïƒ_market
                                      â”‚
                                      â–¼
                         Bayesian Gating / Meta-Inference
                                      â”‚
                                      â–¼
                             P_final Â± Ïƒ_final
```

## ML Components (deep dive)

### 1ï¸âƒ£ Bayesian NBA Win Probability Model (core ML)

This is your anchor model.

**Inputs**
- Team latent strength (learned)
- Home court
- Rest days
- Back-to-back
- Injuries (binary or severity-weighted)
- Travel distance
- Recent form (rolling window)

**Model**
- Hierarchical Bayesian logistic regression

**Key idea**
- Each team has a latent strength parameter
- Strength evolves slowly over time
- Priors prevent overfitting early in season

**Mathematically**
```
logit(P(home_win)) =
  (Î¸_home âˆ’ Î¸_away)
  + Î²_rest
  + Î²_home
  + Î²_injuries

Î¸_team ~ Normal(Î¼_league, Ïƒ_league)
Time evolution: random walk or Kalman-style update
```

**Why AI labs like this**
- Youâ€™re modeling structure
- Youâ€™re explicit about uncertainty
- You can explain failures

### 2ï¸âƒ£ Market Belief Dynamics Model

Instead of â€œthe market priceâ€, model how beliefs move.

**Features**
- Price velocity
- Volume spikes
- Liquidity
- Time-to-game
- Entropy / dispersion of orders

**Model options**
- Bayesian state-space model
- Kalman filter over implied probability
- Neural sequence encoder â†’ Bayesian output head

This answers: **â€œIs this move informative or noise?â€**

### 3ï¸âƒ£ Bayesian Gating Model (this is the money)

This is the most AI-lab-coded part.

Youâ€™re not just averaging probabilities â€” youâ€™re learning who to trust and when.

**Inputs**
- |P_model âˆ’ P_market|
- Ïƒ_model
- Ïƒ_market
- Liquidity
- Time remaining
- Historical calibration error

**Model**
- Bayesian mixture of experts

```
P_final = w * P_model + (1 âˆ’ w) * P_market
w ~ Beta(Î±(x), Î²(x))
```

Where `w` is learned, not fixed.

This gives you:
- Interpretable trust weights
- Uncertainty-aware blending
- Graceful degradation

### 4ï¸âƒ£ Neural Enhancement (used correctly)

Neural nets are tools, not the thesis.

Use them for:
- Team embeddings (learn latent team vectors)
- Injury impact encoding
- News/sentiment embeddings (optional)

But keep Bayesian inference at the top level.

## Evaluation (important)

You donâ€™t evaluate on PnL.

You evaluate on:
- Brier score
- Log loss
- Calibration curves
- Reliability diagrams
- Sharpness vs accuracy

Thatâ€™s exactly how real forecasting systems are evaluated.

## Web App (minimal but serious)

**Pages**
- Dashboard: games ranked by marketâ€“model disagreement
- Game Detail: probability trajectories, trust weight evolution, uncertainty bands
- Research: calibration plots, model vs market breakdown

**APIs**
- `GET /games`
- `GET /games/{id}`
- `POST /forecast`
- `GET /evaluation/calibration`

This shows you can build infra around ML, not just train models.

## What this signals to AI labs

Theyâ€™ll see:
- Probabilistic modeling maturity
- Uncertainty reasoning
- Time-series inference
- System design
- Research framing
- Clean abstraction boundaries

This reads much closer to:

â€œI could work on forecasting / inference / evaluation infraâ€

than:

â€œI built a sports betting modelâ€

## Recommended build order

1. Bayesian NBA win model (offline)
2. Market odds ingestion + alignment
3. Gating model (static)
4. Time evolution
5. Web API
6. Frontend
7. Optional neural enhancements
